{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Naive Bayes Classifier\n",
    "\n",
    "## Submission rules\n",
    "\n",
    "1. Lab 1 is an assignment for teams of 2-3 students; the teams are listed on cms. Please make only one submission per team\n",
    "2. The assignment should be completed in a Google Collaboratory notebook (https://colab.research.google.com/notebooks/intro.ipynb#). To this end, first create a copy of this notebook in your personal Googel Drive via \"File\" --> \"Save a copy in Drive\". Do not forget to    \n",
    " *    rename the notebook and mention all your teammates in the name;      \n",
    " *    share your notebook within ucu.edu.ua domain, so that we will be able to open and grade it :)  \n",
    "3. Submit the link to the final version of the notebook in the comments field of cms and list all the team members therein. No changes may be made to the notebook after the deadline\n",
    "4. At the top of your notebook, provide a work-breakdown structure estimating efforts of each team member.\n",
    "\n",
    "Failure to comply with the submission rules can be a reason of up to 1 point deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1O-SSLytW2k"
   },
   "source": [
    "## Introduction\n",
    "During the past three weeks, you learned a couple of essential notions ant theorems. One of them is Bayes theorem.\n",
    "\n",
    "One of its applications is **Naive Bayes classifier**, which is a probabilistic classifier whose aim is to determine which class some observation probably belongs by using the Bayes formula:\n",
    "$$\\mathsf{P}(\\mathrm{class}\\mid \\mathrm{observation})=\\frac{\\mathsf{P}(\\mathrm{observation}\\mid\\mathrm{class})\\mathsf{P}(\\mathrm{class})}{\\mathsf{P}(\\mathrm{observation})}$$\n",
    "\n",
    "Under the strong independence assumption, one can calculate $\\mathsf{P}(\\mathrm{observation} \\mid \\mathrm{class})$ as\n",
    "$$\\mathsf{P}(\\mathrm{observation}) = \\prod_{i=1}^{n} \\mathsf{P}(\\mathrm{feature}_i),$$\n",
    "where $n$ is the total number of features describing a given observation. Thus, $\\mathsf{P}(\\mathrm{class}|\\mathrm{observation})$ now can be calculated as\n",
    "\n",
    "$$\\mathsf{P}(\\mathrm{class} \\mid \\mathrm{\\mathrm{observation}}) = \\mathsf{P}(\\mathrm{class})\\times \\prod_{i=1}^{n}\\frac{\\mathsf{P}(\\mathrm{feature}_i\\mid \\mathrm{class})}{\\mathsf{P}(\\mathrm{feature}_i)}$$\n",
    "\n",
    "For more detailed explanation, you can check [this link](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzV_ykevv9Tp"
   },
   "source": [
    "## Data  description\n",
    "\n",
    "There are 5 datasets uploaded on the cms. \n",
    "\n",
    "To determine your variant, take your team number from the list of teams on cms and take *mod 5* - this is the number of your data set.\n",
    "\n",
    "* **0 - authors**\n",
    "This data set consists of citations of three famous writers: Edgar Alan Poe, Mary Wollstonecraft Shelley and HP Lovecraft. The task with this data set is to classify a piece of text with the author who was more likely to write it.\n",
    "\n",
    "* **1 - discrimination**\n",
    "This data set consists of tweets that have discriminatory (sexism or racism) messages or of tweets that are of neutral mood. The task is to determine whether a given tweet has discriminatory mood or does not.\n",
    "\n",
    "* **2 - fake news**\n",
    "This data set contains data of American news: a headline and an abstract of the article.\n",
    "Each piece of news is classified as fake or credible. The task is to classify the news from test.csv as credible or fake.\n",
    "\n",
    "* **3 - sentiment**\n",
    "All the text messages contained in this data set are labeled with three sentiments: positive, neutral or negative. The task is to classify some text message as the one of positive mood, negative or neutral.\n",
    "\n",
    "* **4 - spam**\n",
    "This last data set contains SMS messages classified as spam or non-spam (ham in the data set). The task is to determine whether a given message is spam or non-spam.\n",
    "\n",
    "Each data set consists of two files: *train.csv* and *test.csv*. The first one you will need find the probabilities distributions for each of the features, while the second one is needed for checking how well your classifier works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASP_dWuj9t0l"
   },
   "source": [
    "##Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Cv-5_R7D6bTP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTrain = './data/3-sentiment/train.csv'\n",
    "pathTest = './data/3-sentiment/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvZsfHRL6JOA"
   },
   "source": [
    "### Data pre-processing\n",
    "* Read the *.csv* data files with *pandas* package. This package will also provide you with a nice interface for data processing even within the classifier implementation.\n",
    "* Сlear your data from punctuation or other unneeded symbols.\n",
    "* Clear you data from stop words. You don’t want words as is, and, or etc. to affect your probabilities distributions, so it is a wise decision to get rid of them. Find list of stop words in the cms under the lab task.\n",
    "* Represent each test message as its bag-of-words. [Here](https://machinelearningmastery.com/gentle-introduction-bag-words-model/) you can find general introduction to the bag-of-words model and examples on to create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "XeSKb6pQ9DoL",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0       according gran company plans move production r...\n",
      "1       technopolis plans develop stages area less squ...\n",
      "2       international electronic industry company elco...\n",
      "3       new production plant company increase capacity...\n",
      "4       according company s updated strategy years bas...\n",
      "                              ...                        \n",
      "3963    agreement benefon s forthcoming range twig int...\n",
      "3964    terms agreement bunge will acquire raisio s ke...\n",
      "3965    transaction agreement metsaliitto will purchas...\n",
      "3966    underground parking facilities will also built...\n",
      "3967    unit prices straddle carriers vary eur eur com...\n",
      "Name: text, Length: 3968, dtype: object, 0        neutral\n",
      "1        neutral\n",
      "2       negative\n",
      "3       positive\n",
      "4       positive\n",
      "          ...   \n",
      "3963     neutral\n",
      "3964     neutral\n",
      "3965     neutral\n",
      "3966     neutral\n",
      "3967     neutral\n",
      "Name: sentiment, Length: 3968, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "def removeSuf(string: str) -> str:\n",
    "    if len(string) > 2 and string[-3:] == 'ing':\n",
    "        string = string[:-3]\n",
    "    else:\n",
    "        if len(string) > 1 and string[-2:] == 'es':\n",
    "            string = string[:-2]\n",
    "        if len(string) > 0 and string[-1] == 's':\n",
    "            string = string[:-1]\n",
    "    return string\n",
    "\n",
    "\n",
    "def simplifyData(string: str, stopWords: set) -> str:\n",
    "    res = []\n",
    "    string = re.sub(r'[^a-zA-Z ]', '', string).lower()\n",
    "    for bigWord in string.split():\n",
    "        if bigWord in stopWords:\n",
    "            continue\n",
    "        for word in bigWord.split('-'):\n",
    "#             res.append(removeSuf(word.lower()))\n",
    "            res.append(word.lower())\n",
    "\n",
    "    return ' '.join([s for s in res if s != \"\"])\n",
    "\n",
    "\n",
    "def process_data(data_file):\n",
    "    \"\"\"\n",
    "    Function for data processing and split it into X and y sets.\n",
    "    :param data_file: str - train datado a research of your own\n",
    "    :return: pd.DataFrame|list, pd.DataFrame|list - X and y data frames or lists\n",
    "    \"\"\"\n",
    "    with open('stop_words.txt', 'r') as f:\n",
    "        stopWordsStr = re.sub(r'[^a-zA-Z\\n]', '', f.read())\n",
    "#         stopWords = set(map(removeSuf, stopWordsStr.split()))\n",
    "        stopWords = set(stopWordsStr.split())\n",
    "        \n",
    "\n",
    "    df = pd.read_csv(data_file)\n",
    "    df['text'] = df['text'].apply(lambda x: simplifyData(x, stopWords))\n",
    "    return df['text'], df['sentiment']\n",
    "\n",
    "print(process_data(pathTrain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95OjORbi9zAW"
   },
   "source": [
    "### Implementation\n",
    "Implement each method of the BayesianClassifier \n",
    "created according to its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "rx2-IVxy-R99"
   },
   "outputs": [],
   "source": [
    "class BayesianClassifier:\n",
    "    \"\"\"\n",
    "    Implementation of Naive Bayes classification algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.numByLabel = {'negative': 0, 'neutral': 0, 'positive': 0}\n",
    "        self.numberUnique = 0\n",
    "        self.numWordsByLabel = {'negative': {}, 'neutral': {}, 'positive': {}}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit Naive Bayes parameters according to train data X and y.\n",
    "        :param X: pd.DataFrame|list - train input/messages all data. X list of strings\n",
    "        :param y: pd.DataFrame|list - train output/labels lables.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        unique_words = set()\n",
    "        for index in range(len(X)):\n",
    "            for word in (X[index].split(\" \")):\n",
    "                unique_words.add(word)\n",
    "                self.numByLabel[y[index]] += 1\n",
    "                self.numWordsByLabel[y[index]][word] = self.numWordsByLabel[y[index]].get(word, 0) + 1\n",
    "\n",
    "        self.numberUnique = len(unique_words)\n",
    "\n",
    "    def predict_prob(self, message, label):\n",
    "        \"\"\"\n",
    "        Calculate the probability that a given label can be assigned to a given message.\n",
    "        :param message: str - input message\n",
    "        :param label: str - label\n",
    "        :return: float - probability P(label|message)\n",
    "        \"\"\"\n",
    "        probability = 1\n",
    "        for word in message.split(\" \"):\n",
    "            probability *= (self.numWordsByLabel[label].get(word, 0) + 1) / (self.numByLabel[label] + self.numberUnique)\n",
    "\n",
    "        return probability\n",
    "\n",
    "    def predict(self, message):\n",
    "        \"\"\"\n",
    "        Predict label for a given message.\n",
    "        :param message: str - message\n",
    "        :return: str - label that is most likely to be truly assigned to a given message\n",
    "        \"\"\"\n",
    "        results_prob = [\"\", 0]\n",
    "        for mood in [\"negative\", \"neutral\", \"positive\"]:\n",
    "            probability = self.predict_prob(message, mood)\n",
    "            if probability > results_prob[1]:\n",
    "                results_prob = [mood, probability]\n",
    "        return results_prob[0]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Return the mean accuracy on the given test data and labels - the efficiency of a trained model.\n",
    "        :param X: pd.DataFrame|list - test data - messages\n",
    "        :param y: pd.DataFrame|list - test labels\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        for i, x in enumerate(X):\n",
    "            if self.predict(x) == y[i]:\n",
    "                correct += 1\n",
    "        return correct / len(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW85An5p-sp3"
   },
   "source": [
    "### Testing\n",
    "*  Finally, after you are done with your classifier, test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "zo4TZVh4950E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score:  0.3143507972665148\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = process_data(pathTrain)\n",
    "test_X, test_y = process_data(pathTest)\n",
    "\n",
    "classifier = BayesianClassifier()\n",
    "classifier.fit(train_X, train_y)\n",
    "classifier.predict_prob(test_X[0], test_y[0])\n",
    "\n",
    "print(\"model score: \", classifier.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkNytMyM-8n0"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "Summarize your work by explaining in a few sentences the points listed below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpEbPLoyBTBA"
   },
   "source": [
    "* ### Describe the method implemented in general:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAivLQzK_Ksa"
   },
   "source": [
    "* ### List pros and cons of the method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW1pCL-ZBfUD"
   },
   "source": [
    "* ### Add a few sencences about your implementation of the classifier:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlIcMe8uBz-2"
   },
   "source": [
    "* ### Describe your results:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PS_Lab1_Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
